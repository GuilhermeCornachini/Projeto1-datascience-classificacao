{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto de portifolio, eu utilizo uma base de dados de uma seguradora que reuniu informações sobre os seus clientes juntamente com o interesse de renovar o contrato. E utilizando ciência de dados eu as faço gerar lucro, predizendo quais os clientes mais provaveis de renovar o contrato.\n",
    "\n",
    "Link da base de dados https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction\n",
    "\n",
    "Principal métrica utilizada: Log loss.\n",
    "\n",
    "Modelos do ensemble: XGB e Logistic regression.\n",
    "\n",
    "Importante! Checar explicações  sobre o threshold e modelos escolhidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando as primeiras linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1   Male   44                1         28.0                   0   \n",
       "1   2   Male   76                1          3.0                   0   \n",
       "2   3   Male   47                1         28.0                   0   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                  26.0      217   \n",
       "1    1-2 Year             No         33536.0                  26.0      183   \n",
       "2   > 2 Years            Yes         38294.0                  26.0       27   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré processamento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste dataset, eu optei por não fazer um pré processamento muito avançado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Response','id'])\n",
    "#Coluna ID removida por não ter valor perditivo e Response por ser o que procuramos \n",
    "Y = train['Response']\n",
    "#Atribuindo a coluna Response ao Y para ser nossa coluna a ser predita\n",
    "X = pd.get_dummies(X)\n",
    "#Comando parecido com o onehotencoder, transformar dados categoricos em colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consertando desbalanceamento de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por conta do desbalanceamento, e para reduzir o tempo de treino, uma redução de linhas com pouco valor preditivo será feita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "NM = NearMiss()\n",
    "X,Y = NM.fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da baseline\n",
    "\n",
    "Agora, como temos uma base balanceada, não temos problema em utilizar a porcentagem simples de acertos, dessa forma não caímos no \"paradoxo da porcentagem\", porém utilizaremos apenas como referência, pois não será nossa principal métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline no split  0 = 76.03082851637765\n",
      "baseline no split  1 = 75.67758509955041\n"
     ]
    }
   ],
   "source": [
    "n_splits = 2\n",
    "aux=0\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "for tr, ts in kf.split(X,Y):  \n",
    "    X_train, Y_train = X.iloc[tr], Y.iloc[tr]\n",
    "    X_test, Y_test = X.iloc[ts], Y.iloc[ts]\n",
    "    print('baseline no split ',aux,'=',X_test['Vehicle_Damage_Yes'].value_counts()[1]/X_test.shape[0]*100)\n",
    "    aux=aux+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica escolhida\n",
    "\n",
    "Para este projeto, eu optei por usar a Logloss como principal por penalizar os erros de predição relativo a probabilidade de pertencer as classes 0 e 1.\n",
    "\n",
    "Além de ficar acompanhando a acurácia simples para ter uma segunda métrica e a matriz de confusão para observar como seria\n",
    "a predição simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para deixar os valores entre 0 e 1, o que melhora o desempenho para modelos lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler()\n",
    "X[X.columns] = MMS.fit_transform(X[X.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renomeando colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pois o XGBoost não aceitam as colunas com determinados caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.rename(columns={'Vehicle_Age_1-2 Year':'Veiculo_1_e_2','Vehicle_Age_< 1 Year':'Veiculo_Menor_1',\n",
    "                     'Vehicle_Age_> 2 Years':'Veiculo_Maior_2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como ficou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Veiculo_1_e_2</th>\n",
       "      <th>Veiculo_Menor_1</th>\n",
       "      <th>Veiculo_Maior_2</th>\n",
       "      <th>Vehicle_Damage_No</th>\n",
       "      <th>Vehicle_Damage_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.982699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.826990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.934256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93415</th>\n",
       "      <td>0.317460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046282</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.619377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93416</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93417</th>\n",
       "      <td>0.412698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059738</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.543253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93418</th>\n",
       "      <td>0.650794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.446367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93419</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093226</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.536332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93420 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0      0.476190              1.0     0.557692                 0.0   \n",
       "1      0.412698              1.0     0.538462                 0.0   \n",
       "2      0.412698              1.0     0.538462                 0.0   \n",
       "3      0.238095              1.0     0.538462                 0.0   \n",
       "4      0.158730              1.0     0.538462                 0.0   \n",
       "...         ...              ...          ...                 ...   \n",
       "93415  0.317460              1.0     0.884615                 0.0   \n",
       "93416  0.333333              1.0     0.538462                 0.0   \n",
       "93417  0.412698              1.0     0.538462                 0.0   \n",
       "93418  0.650794              1.0     0.538462                 0.0   \n",
       "93419  0.285714              1.0     0.538462                 0.0   \n",
       "\n",
       "       Annual_Premium  Policy_Sales_Channel   Vintage  Gender_Female  \\\n",
       "0            0.000000              0.759259  0.103806            0.0   \n",
       "1            0.000000              0.154321  0.982699            0.0   \n",
       "2            0.000000              0.154321  0.034602            0.0   \n",
       "3            0.000000              0.956790  0.826990            1.0   \n",
       "4            0.000000              0.956790  0.934256            1.0   \n",
       "...               ...                   ...       ...            ...   \n",
       "93415        0.046282              0.154321  0.619377            0.0   \n",
       "93416        0.064641              0.759259  0.307958            1.0   \n",
       "93417        0.059738              0.759259  0.543253            1.0   \n",
       "93418        0.076730              0.154321  0.446367            1.0   \n",
       "93419        0.093226              0.154321  0.536332            1.0   \n",
       "\n",
       "       Gender_Male  Veiculo_1_e_2  Veiculo_Menor_1  Veiculo_Maior_2  \\\n",
       "0              1.0            1.0              0.0              0.0   \n",
       "1              1.0            1.0              0.0              0.0   \n",
       "2              1.0            1.0              0.0              0.0   \n",
       "3              0.0            1.0              0.0              0.0   \n",
       "4              0.0            1.0              0.0              0.0   \n",
       "...            ...            ...              ...              ...   \n",
       "93415          1.0            1.0              0.0              0.0   \n",
       "93416          0.0            1.0              0.0              0.0   \n",
       "93417          0.0            1.0              0.0              0.0   \n",
       "93418          0.0            1.0              0.0              0.0   \n",
       "93419          0.0            1.0              0.0              0.0   \n",
       "\n",
       "       Vehicle_Damage_No  Vehicle_Damage_Yes  \n",
       "0                    0.0                 1.0  \n",
       "1                    0.0                 1.0  \n",
       "2                    0.0                 1.0  \n",
       "3                    0.0                 1.0  \n",
       "4                    0.0                 1.0  \n",
       "...                  ...                 ...  \n",
       "93415                0.0                 1.0  \n",
       "93416                0.0                 1.0  \n",
       "93417                0.0                 1.0  \n",
       "93418                0.0                 1.0  \n",
       "93419                0.0                 1.0  \n",
       "\n",
       "[93420 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando modelos de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.2048615473277506\n",
      "Acurácia 0.9087133376150717\n",
      "Matriz de confusão:\n",
      "[[23268     8]\n",
      " [ 4256 19178]]\n",
      "\n",
      "Log loss: 0.20650136695932925\n",
      "Acurácia 0.9088203810747163\n",
      "Matriz de confusão:\n",
      "[[23425     9]\n",
      " [ 4250 19026]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000,penalty='none')\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "\n",
    "for tr, ts in kf.split(X,Y):\n",
    "    X_train, Y_train = X.iloc[tr], Y.iloc[tr]\n",
    "    X_test, Y_test = X.iloc[ts], Y.iloc[ts]\n",
    "    \n",
    "    lr.fit(X_train, Y_train)\n",
    "    prev = lr.predict_proba(X_test)[:,1]\n",
    "    print(\"Log loss:\",log_loss(Y_test,prev))\n",
    "    prev = (prev > 0.5).astype(int)\n",
    "    print('Acurácia',accuracy_score(Y_test,prev))\n",
    "    print(\"Matriz de confusão:\")\n",
    "    print(confusion_matrix(Y_test,prev))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.200551038584103\n",
      "Acurácia 0.9089916506101478\n",
      "Matriz de confusão:\n",
      "[[22902   374]\n",
      " [ 3877 19557]]\n",
      "\n",
      "Log loss: 0.2019008549011119\n",
      "Acurácia 0.9080924855491329\n",
      "Matriz de confusão:\n",
      "[[22982   452]\n",
      " [ 3841 19435]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "\n",
    "for tr, ts in kf.split(X,Y):\n",
    "    X_train, Y_train = X.iloc[tr], Y.iloc[tr]\n",
    "    X_test, Y_test = X.iloc[ts], Y.iloc[ts]\n",
    "    \n",
    "    XGB.fit(X_train, Y_train)\n",
    "    prev = XGB.predict_proba(X_test)[:,1]\n",
    "    print(\"Log loss:\",log_loss(Y_test,prev))\n",
    "    prev = (prev > 0.5).astype(int)\n",
    "    print('Acurácia',accuracy_score(Y_test,prev))\n",
    "    print(\"Matriz de confusão:\")\n",
    "    print(confusion_matrix(Y_test,prev))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.8635227518820908\n",
      "Acurácia 0.8891886105758938\n",
      "Matriz de confusão:\n",
      "[[21449  1827]\n",
      " [ 3349 20085]]\n",
      "\n",
      "Log loss: 0.8899915084210891\n",
      "Acurácia 0.8907728537786341\n",
      "Matriz de confusão:\n",
      "[[21687  1747]\n",
      " [ 3355 19921]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_leaf=8)\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "for tr, ts in kf.split(X,Y):\n",
    "    X_train, Y_train = X.iloc[tr], Y.iloc[tr]\n",
    "    X_test, Y_test = X.iloc[ts], Y.iloc[ts]\n",
    "\n",
    "    dt.fit(X_train, Y_train)\n",
    "    prev = dt.predict_proba(X_test)[:,1]\n",
    "    print(\"Log loss:\",log_loss(Y_test,prev))\n",
    "    prev = (prev > 0.5).astype(int)\n",
    "    print('Acurácia',accuracy_score(Y_test,prev))\n",
    "    print(\"Matriz de confusão:\")\n",
    "    print(confusion_matrix(Y_test,prev))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble escolhido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o ensemble final, eu optei por uma média ponderada do XGB e Logistic regression, sendo respectivamente 0.9 e 0.1, pois foi a combinação que me deu melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.19604574945096742\n",
      "Acurácia 0.9085634767715692\n",
      "Matriz de confusão:\n",
      "[[22792   484]\n",
      " [ 3787 19647]]\n",
      "\n",
      "Log loss: 0.19696650902770135\n",
      "Acurácia 0.9095054592164419\n",
      "Matriz de confusão:\n",
      "[[22961   473]\n",
      " [ 3754 19522]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000,penalty='none')\n",
    "xgb = XGBClassifier(n_estimators=431,learning_rate=0.09751,max_depth=2,min_child_weight=18)\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "for tr, ts in kf.split(X,Y):\n",
    "    X_train, Y_train = X.iloc[tr], Y.iloc[tr]\n",
    "    X_test, Y_test = X.iloc[ts], Y.iloc[ts]\n",
    "    \n",
    "    lr.fit(X_train, Y_train)\n",
    "    xgb.fit(X_train, Y_train)\n",
    "    prev = lr.predict_proba(X_test)[:,1]\n",
    "    prev2 = xgb.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    prev3 = prev*0.1+prev2*0.9\n",
    "        \n",
    "    print(\"Log loss:\",log_loss(Y_test,prev3))\n",
    "    prev3 = (prev3 > 0.4).astype(int)\n",
    "    #Threshold\n",
    "    print('Acurácia',accuracy_score(Y_test,prev3))\n",
    "    print(\"Matriz de confusão:\")\n",
    "    print(confusion_matrix(Y_test,prev3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações importantes:\n",
    "\n",
    "### A logistic regression foi muito boa para detectar falsos positivos\n",
    "### A decision tree foi conseguiu o menor número de falsos negativos\n",
    "### O XGB conseguiu equilibrar as previsões, mantendo um meio termo entre falsos positivos e negativos\n",
    "Combinando o XGB e a logistic regression e utilizando um threshold de 0.4 eu consegui equilibrar melhor, porém tudo depende da ocasião, em casos que os falsos positivos não são bem vindos o melhor seria a logistic regression ou aumentar o threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições na base de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-treino dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.09751, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=18, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=431, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression(max_iter=1000,penalty='none')\n",
    "xgb_final = XGBClassifier(n_estimators=431,learning_rate=0.09751,max_depth=2,min_child_weight=18)\n",
    "\n",
    "lr_final.fit(X,Y)\n",
    "xgb_final.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento na base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardando o id de cada cliente a ser previsto\n",
    "df_resultados['id'] = test['id']\n",
    "\n",
    "#Dropando a coluna teste\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "#Transformação similar a onehotencoder\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "#Normalizando os dados\n",
    "test[test.columns] = MMS.transform(test[test.columns])\n",
    "\n",
    "#Renomeando as colunas\n",
    "test = test.rename(columns={'Vehicle_Age_1-2 Year':'Veiculo_1_e_2','Vehicle_Age_< 1 Year':'Veiculo_Menor_1',\n",
    "                     'Vehicle_Age_> 2 Years':'Veiculo_Maior_2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_lr_final = lr_final.predict_proba(test)[:,1]\n",
    "previsoes_xgb_final =xgb_final.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98476972, 0.99991974, 0.99952136, ..., 0.97009897, 0.96144305,\n",
       "       0.96586568])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_ensemble_final = previsoes_lr_final*0.1+previsoes_xgb_final*0.9\n",
    "#Média ponderada entre os modelos\n",
    "\n",
    "previsoes_ensemble_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados['Porcentagem'] = previsoes_ensemble_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = (previsoes_ensemble_final > 0.4).astype(int)\n",
    "df_resultados['Binario'] = prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127037, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenando pela porcentagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Porcentagem</th>\n",
       "      <th>Binario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65648</th>\n",
       "      <td>446758</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63688</th>\n",
       "      <td>444798</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99125</th>\n",
       "      <td>480235</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31480</th>\n",
       "      <td>412590</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71921</th>\n",
       "      <td>453031</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62773</th>\n",
       "      <td>443883</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109870</th>\n",
       "      <td>490980</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27941</th>\n",
       "      <td>409051</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84795</th>\n",
       "      <td>465905</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49483</th>\n",
       "      <td>430593</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127037 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Porcentagem  Binario\n",
       "65648   446758     0.999989        1\n",
       "63688   444798     0.999989        1\n",
       "99125   480235     0.999988        1\n",
       "31480   412590     0.999987        1\n",
       "71921   453031     0.999987        1\n",
       "...        ...          ...      ...\n",
       "62773   443883     0.000409        0\n",
       "109870  490980     0.000408        0\n",
       "27941   409051     0.000397        0\n",
       "84795   465905     0.000391        0\n",
       "49483   430593     0.000383        0\n",
       "\n",
       "[127037 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados = df_resultados.sort_values(by='Porcentagem', ascending = False)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais \n",
    "\n",
    "Conseguimos utilizar os dados de forma a gerar valor para a empresa, no caso ultrapassamos a baseline fazendo um ensamble. Para projetos futuros há a possibilidade de aplicar deep learning, como também utilizar o stacking de forma a melhorar os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Bayesian optimization para tunar os parametros do XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo(params):\n",
    "    n_estimators=params[0]\n",
    "    learning_rate=params[1]\n",
    "    max_depth=params[2]\n",
    "    min_child_weight=params[3]\n",
    "    \n",
    "    modelo = XGBClassifier(n_estimators=n_estimators,\n",
    "                       learning_rate=learning_rate,\n",
    "                       max_depth=max_depth,\n",
    "                       min_child_weight=min_child_weight\n",
    "                       )\n",
    "    modelo.fit(X_train,Y_train.values.ravel())\n",
    "    previsoes = modelo.predict_proba(X_test)[:,1]\n",
    "    log = log_loss(Y_test, previsoes)\n",
    "    print(params,\" Log:\", log,'\\n',)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parametros = [(100,1000),\n",
    "           (0.0001,0.1),\n",
    "           (1,10),\n",
    "           (1,20)\n",
    "        ]\n",
    "from skopt import gp_minimize\n",
    "resultados_gp = gp_minimize(treinar_modelo, parametros, random_state=0, verbose=0, n_calls=30)\n",
    "print('Final', \" Parametros: \",resultados_gp.x, \" Resultado: \",resultados_gp.fun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
